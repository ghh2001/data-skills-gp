---
title: "OES Data Scraping"
author: "simplymathematics"
date: "October 18, 2018"
output: html_document
---
# Dependencies
```{r}
require(curl)
require(stringr)
require(XML)
```
# Downloading Data

This section downloads a single page. However, it can be modified to work across similar pages. Notice how that would only require changing the code  in the URL. TODO get a list of pertinent OES codes. 
```{r}
raw.data <- curl_download("https://www.bls.gov/oes/current/oes151111.htm", "OES_dollars.txt")
raw.data <- readLines("https://www.bls.gov/oes/current/oes151111.htm")
```

Since we're only interested in the first table, we'll cut everything else out.
```{r}
# Regex for all text between two table
first <- which(grepl("<table border=\"1\"", raw.data))[1]
last <- which(grepl("</table>", raw.data))[1]
truncated.data <- raw.data[first:last]
```

```{r}
html.data <- data.frame(readHTMLTable(truncated.data))
colnames(html.data) <- c("No. of Employees", "RSE", "Mean Hourly Wage", "Mean Annual Wage", "Wage RSE")
html.data
```

Below is an attempt to automate the above process to work with a list of URLs. It doesn't work yet. 
```{r}
oes_scrape <- function(URLs){
  big.data <- data.frame(c("No. of Employees", "RSE", "Mean Hourly Wage", "Mean Annual Wage", "Wage RSE"))
  for url in length(URLS){
    raw.data <- readLines(url)
    first <- which(grepl("<table border=\"1\"", raw.data))[1]
    last <- which(grepl("</table>", raw.data))[1]
    truncated.data <- raw.data[first:last]
    html.data <- data.frame(readHTMLTable(truncated.data))
    colnames(html.data) <- c("No. of Employees", "RSE", "Mean Hourly Wage", "Mean Annual Wage", "Wage RSE")
    merge(big.data, html.data)
  }
}

```